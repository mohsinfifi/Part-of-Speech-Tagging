{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple bidirectional LSTM-CRF model for POS tagging\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        # Word embedding layer\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Bidirectional LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # Initialize the transition parameters with a valid sequence\n",
    "        self.transitions.data[tag_to_ix['START_TAG'], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix['STOP_TAG']] = -10000\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Get the emission scores from the LSTM\n",
    "        embeds = self.word_embeds(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "\n",
    "        # Compute the scores from the hidden state\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "\n",
    "        return tag_space\n",
    "\n",
    "# Define functions for training and evaluating the model\n",
    "def train(model, optimizer, sentence, tags):\n",
    "    model.zero_grad()\n",
    "    sentence = torch.tensor(sentence, dtype=torch.long)\n",
    "    tags = torch.tensor(tags, dtype=torch.long)\n",
    "\n",
    "    tag_scores = model(sentence)\n",
    "\n",
    "    # Calculate the negative log-likelihood for CRF\n",
    "    loss = model.neg_log_likelihood(tag_scores, tags)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(model, sentence):\n",
    "    with torch.no_grad():\n",
    "        sentence = torch.tensor(sentence, dtype=torch.long)\n",
    "        tag_scores = model(sentence)\n",
    "        _, predicted_tags = model.crf_decode(tag_scores)\n",
    "        return predicted_tags\n",
    "\n",
    "# Sample data (you should replace this with your own dataset)\n",
    "sentence = [1, 2, 3, 4, 5]  # Replace with your word indices\n",
    "tags = [0, 1, 1, 2, 0]      # Replace with your POS tag indices\n",
    "\n",
    "# Define the mapping from tags to indices (START_TAG and STOP_TAG should be included)\n",
    "tag_to_ix = {\"START_TAG\": 0, \"STOP_TAG\": 1, \"NOUN\": 2, \"VERB\": 3}\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 50\n",
    "hidden_dim = 50\n",
    "vocab_size = len(word_to_ix)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Create the model\n",
    "model = BiLSTMCRF(vocab_size, tag_to_ix, embedding_dim, hidden_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    loss = train(model, optimizer, sentence, tags)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "\n",
    "# Evaluation\n",
    "predicted_tags = evaluate(model, sentence)\n",
    "print(\"Predicted Tags:\", predicted_tags)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
